# -*- coding: utf-8 -*-
"""Deep Learning Lab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tiD1wdnmV7MYl0HjWmehBatHIPLo_D2Q
"""

#1. Create neural network class and initialize those weights and biases.
from math import sqrt
from numpy import mean
from numpy.random import rand
from matplotlib import pyplot
n = 10
lower, upper = -(1.0/sqrt(n)), (1.0/sqrt(n))
numbers = rand(1000)
scaled = lower + numbers * (upper - lower)
print(lower,upper)
print(scaled.min(), scaled.max())
print(scaled.mean(), scaled.std())
values = [i for i in range(1,101)]
results = [1.0/sqrt(n) for n in values]
pyplot.errorbar(values, [0.0 for _ in values], yerr = results)
pyplot.show()

#2. Implement all activation functions in Neural Network.
import numpy as np
def threshold(x,th):
  y=[]
  for i in x:
    if i>=th:
      y.append(1)
    else:
      y.append(0)
  return y
x=np.arange(-10,10,1)
#x = np.linspace(-10,10,20)
y=threshold(x,0)
import matplotlib.pyplot as plt
plt.figure(figsize=(4,4))
plt.plot(x,y,'k-s',markersize='10',markerfacecolor='w',markeredgecolor='turquoise')
plt.xlabel('X->')
plt.ylabel('Y->')
plt.title('Threshold activation function')
plt.show()

#Sigmoid function
def sigmoid(x):
  return 1/(1+np.exp(-x))
x=np.arange(-10,10,0.1)
y=sigmoid(x)
plt.plot(x,y,'r-')
plt.title('Sigmoid Function')
plt.show()

# WAP to implement RAMP & linear activation function
# linear y=f(x)=x
# ramp y=f(x)= {0 if x< 0 else x}
def ramp(x):
  y=[]
  for i in x:
    if i<0:
      y.append(0)
    else:
      y.append(i)
  return y
x=np.arange(-1,1,0.01)
y1=x # linear
y2=ramp(x) # ramp
y3=sigmoid(x)
y4=threshold(x,0)
#plot
import matplotlib.pyplot as plt
plt.figure(figsize=(4,4))
plt.plot(x,y1,label='Linear')
plt.plot(x,y2,label='Ramp')
plt.plot(x,y3,label='sigmoid')
plt.plot(x,y4,label='threshold')
plt.legend()
plt.show()

plt.figure(figsize = (5,5))
plt.subplot(3,3,1)
plt.plot(x,y1)
plt.title('Linear')
plt.subplot(3,3,3)
plt.plot(x,y2)
plt.title('Ramp')
plt.subplot(3,3,5)
plt.plot(x,y3)
plt.title('Sigmoid')
plt.subplot(3,3,9)
plt.plot(x,y4)
plt.title('Treshold')
plt.show()

#3. Implement Loss function for Neural network.
import math
import numpy as np
import matplotlib.pyplot as plt
y = np.array([-3,-1,-2,1,-1,1,2,1,3,4,3,5])
yhat = np.array([-2,1,-1,0,-1,1,2,2,3,3,3,5])
x = list(range(len(y)))
plt.figure(figsize=(9,5))
plt.scatter(x,y,label='original',color='red')
plt.plot(x,yhat,color='cyan',label='predicted')
plt.legend()
plt.show()
#Calculate MSE
d = y-yhat
mse_f = np.mean(d**2)
print("Mean Squared Error: ",mse_f)
#Calculate MAE
mae_f = np.mean(abs(d))
print("Mean Absolute Error: ",mae_f)

#Huber Loss Function
import numpy as np
import matplotlib.pyplot as plt
def huber(a, delta):
  value = np.where(np.abs(a)<delta, 0.5*a**2, delta*(np.abs(a)- 0.5*delta))
  deriv = np.where(np.abs(a)<delta, a, np.sign(a)*delta)
  return value, deriv
h, d = huber(np.arange(-1,1,0.01), delta = 0.2)
fig, ax = plt.subplots(1)
ax.plot(h, label = 'loss value')
ax.plot(d, label = 'loss derivative')
ax.grid(True)
ax.legend()

#Cross-Entropy Loss Function
from math import log
from numpy import mean
#Calculate cross-entropy
def cross_entropy_funct(p,q): return -sum([p[i]*log(q[i]) for i in range (len(p))])
#Define classification data p, q
p = [1,1,1,1,1,0,0,0,0,0]
q = [0.7,0.9,0.8,0.8,0.6,0.2,0.1,0.4,0.1,0.3]
#Calculate cross-entropy for each example
results = list()
for i in range (len(p)):
#create the distribution for each event {0,1}
  expected = [1.0 - p[i], p[i]]
  predicted = [1.0 - q[i], q[i]]
#Calculate cross-entropy for the two events
  cross = cross_entropy_funct(expected,predicted)
  print('>[y = %.1f, yhat = %.1f] cross entropy: %.3f'%(p[i], q[i], cross))
  results.append(cross)
#Caculate the Average cross entropy
mean_cross_entropy = mean(results)
print('\nAverage Cross Entropy: %.3f'%mean_cross_entropy)

#4. Implement Forward Propagation and Backward Propagation.
from joblib.numpy_pickle_utils import xrange
from numpy import *
class NeuralNet(object):
  def __init__(self):
    random.seed(1)
    self.synaptic_weights = 2*random.random((3,1))-1
  def __sigmoid(self,x):
      return 1 / (1+exp(-x))
  def __sigmoid_derivative(self,x):
      return x*(1-x)
  def train(self, inputs, outputs, training_iterations):
      for iteration in xrange(training_iterations):
        output = self.learn(inputs)
        error = outputs - output
        factor = dot(inputs.T, error * self.__sigmoid_derivative(output))
        self.synaptic_weights += factor
  def learn(self, inputs):
      return self.__sigmoid(dot(inputs, self.synaptic_weights))
if __name__ == "__main__":
  neural_network = NeuralNet()

  inputs = array([[0,1,1], [1,0,0], [1,0,1]])
  outputs = array([[1,0,1]]).T
  neural_network.train(inputs, outputs, 10000)
  print(neural_network.learn(array([1,0,1])))

#5. Program to Train and Test a neural network.
import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import keras
import seaborn as sns
from keras.models import Sequential
from keras.layers import Dense
from sklearn.metrics import confusion_matrix
data=pd.read_csv('/content/drive/MyDrive/heart.csv')
data.head()

data.describe()

data.isnull().any()

x=data.iloc[:,:13].values
y=data['target'].values
x

y

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(x,y,test_size=0.3,random_state=0)
from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_train=sc.fit_transform(X_train)
X_test=sc.transform(X_test)

X_train=pd.DataFrame(x_train)
X_train.head()

X_test=pd.DataFrame(X_test)
X_test.head()

classifier=Sequential()
classifier.add(Dense(activation='relu',input_dim=13,units=8,kernel_initializer='uniform'))
classifier.add(Dense(activation='relu',units=14,kernel_initializer='uniform'))
classifier.add(Dense(activation='sigmoid',units=1,kernel_initializer='uniform'))
classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
classifier.fit(X_train,Y_train,batch_size=8,epochs=100)

y_pred=classifier.predict(X_test)
y_pred=(y_pred>0.45)
cm=confusion_matrix(Y_test,y_pred)
cm

accuracy=(cm[0][0]+cm[1][1])/(cm[0][1]+cm[1][0]+cm[0][0]+cm[1][1])
print(accuracy*100)

#CNN Implementation
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from itertools import product

plt.rc('figure', autolayout = True)
plt.rc('image', cmap = 'magma')

kernel = tf.constant([[-1,-1,-1],
                      [-1,8,-1],
                      [-1,-1,-1],
                      ])

image = tf.io.read_file('/content/drive/MyDrive/Swaraj.jpg')
image = tf.io.decode_jpeg(image, channels = 1)
image = tf.image.resize(image, size = [300,300])

img = tf.squeeze(image).numpy()
plt.figure(figsize = (5,5))
plt.imshow(img, cmap = 'gray')
plt.axis('off')
plt.title('Original Gray Scale Imgae')
plt.show()

image = tf.image.convert_image_dtype(image, dtype = tf.float32)
image = tf.expand_dims(image, axis = 0)
kernel = tf.reshape(kernel, [*kernel.shape, 1, 1])
kernel = tf.cast(kernel, dtype = tf.float32)

conv_fn = tf.nn.conv2d

image_filter = conv_fn(
    input = image,
    filters = kernel,
    strides = 1, # or (1,1)
    padding = 'SAME',
)
plt.figure(figsize = (15,5))

plt.subplot(1, 3, 1)
plt.imshow(
    tf.squeeze(image_filter)
)
plt.axis('off')
plt.title('Convolution')

relu_fn = tf.nn.relu

image_detect = relu_fn(image_filter)
plt.subplot(1, 3, 2)
plt.imshow(
    tf.squeeze(image_detect)
)
plt.axis('off')
plt.title('Activation')

pool = tf.nn.pool
image_condense = pool(input = image_detect,
                      window_shape = (2,2),
                      pooling_type = 'MAX',
                      strides = (2,2),
                      padding = 'SAME',
                      )
plt.subplot(1, 3, 3)
plt.imshow(tf.squeeze(image_condense))
plt.axis('off')
plt.title('Pooling')
plt.show()

#6. Train and test the Convolution neural network using the heart disease dataset, pre-process it
import tensorflow as tf
import numpy as np
import pandas as pd
import keras
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

#Load the dataset
heart_data = pd.read_csv('/content/drive/MyDrive/heart.csv')

#Split features and target variables
X = heart_data.drop(columns=['target'])
y = heart_data['target']

#Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)

#Standardize Features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Reshape the data to to fit a 1D CNN Model
X_train = np.expand_dims(X_train, axis = 2)
X_test = np.expand_dims(X_test, axis = 2)

#Build the CNN Model
model = tf.keras.Sequential([
    tf.keras.layers.Conv1D(64, 3, activation = 'relu', input_shape = (X_train.shape[1], 1)),
    tf.keras.layers.MaxPooling1D(2),
    tf.keras.layers.Conv1D(32, 3, activation = 'relu'),
    tf.keras.layers.GlobalAveragePooling1D(),
    tf.keras.layers.Dense(1, activation = 'sigmoid')
])

#Compile Model
model.compile(optimizer = 'adam',
              loss = 'binary_crossentropy',
              metrics = ['accuracy'])

#Train the model
model.fit(X_train, y_train, epochs = 50, batch_size = 32, validation_split = 0.1, verbose = 2)

#Test the model
y_pred = (model.predict(X_test)>0.5).astype("int32")
test_accuracy = accuracy_score(y_test, y_pred)
print("\nTest Accuracy: ", test_accuracy)

#7. Implement Convolution neural network for image classification.
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

#Normalize pixel values to be between 0 and 1
train_images, test_images = train_images/255.0, test_images/255.0

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

plt.figure(figsize = (10,10))
for i in range(25):
  plt.subplot(5, 5, i+1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(train_images[i])
  plt.xlabel(class_names[train_labels[i][0]])
plt.show()

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64,(3,3)))

#8. Train and test the recurrent neural network using the heart disease dataset, pre-process it.

#9. Implement Facial recognition using neural network.

#10. Implement Object detection using neural network.